{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "import helper\n",
    "from feature_optimization import FeatureOptimizer\n",
    "import feature_opt_functions as funcs\n",
    "from indices import *\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import jaccard_score, average_precision_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 4)\n",
      "(92, 4)\n"
     ]
    }
   ],
   "source": [
    "dictOfStressedImageNames = {}\n",
    "for v in helper.getStressedImagesNames('stress_date.xlsx'):\n",
    "    if v is not None:\n",
    "        dictOfStressedImageNames[v[0]] = v[1]\n",
    "\n",
    "dictOfReferenceImageNames = {}\n",
    "for v in helper.getStressedImagesNames('reference_date.xlsx'):\n",
    "    if v is not None:\n",
    "        dictOfReferenceImageNames[v[0]] = v[1]\n",
    "\n",
    "tilesPerGroup = None\n",
    "with open(os.path.join(\"subdivs\", \"tiles_2img_2.json\"), 'r') as fout:\n",
    "    tilesPerGroup = json.load(fout)\n",
    "\n",
    "train_tiles = tilesPerGroup[0]\n",
    "test_tiles = tilesPerGroup[1]\n",
    "\n",
    "train_data = helper.getH_and_S(dictOfStressedImageNames, train_tiles)\n",
    "train_data_ref = helper.getH_and_S(dictOfReferenceImageNames, train_tiles)\n",
    "test_data = helper.getH_and_S(dictOfStressedImageNames, test_tiles)\n",
    "test_data_ref = helper.getH_and_S(dictOfReferenceImageNames, test_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inform_cache = {}\n",
    "indep_cache = {}\n",
    "\n",
    "data = [None]*2\n",
    "data[0] = helper.leaveFinite(train_data[0])\n",
    "data[1] = helper.leaveFinite(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(informativeness_treshold, independency_treshold):\n",
    "    # BEGIN FEATURE OPTIMIZER BLOCK\n",
    "    print(\"-\"*33)\n",
    "    print(\"START NEW MODEL\")\n",
    "    print(\"INFO:\", informativeness_treshold, \"INDEP:\", independency_treshold)\n",
    "    print(\"Feature Optimization\")\n",
    "    args = { \n",
    "        \"num_generations\":150, \n",
    "        \"num_parents_mating\":3,\n",
    "        \"parent_selection_type\":\"sss\",\n",
    "        \"keep_elitism\":1,\n",
    "        \"sol_per_pop\":150,\n",
    "\t\t\"mutation_probability\":0.25,\n",
    "        \"parallel_processing\":8\n",
    "        }\n",
    "    \n",
    "    encoder = IndicesClassEncoderEq([HueSimp, B, NORMP, DIST2], list(range(1, 12)))\n",
    "    print(f\"Avaible features: {encoder.total_length}\")\n",
    "\n",
    "    opt = FeatureOptimizer(encoder, 48,\n",
    "                           funcs.bhattacharyya_distance, \n",
    "                           funcs.spearman_independency, \n",
    "                           optimization_method=\"genetic\",\n",
    "                           optimizer_args=args,\n",
    "                           informativeness_threshold=informativeness_treshold, \n",
    "                           independency_threshold=independency_treshold,\n",
    "                           set_independency='weighted_harmonic_mean')\n",
    "    \n",
    "    opt.informativeness_cache = inform_cache\n",
    "    opt.independency_cache = indep_cache\n",
    "\n",
    "    opt.fit(data, data[1], False)\n",
    "    # END FEATURE OPTIMIZER BLOCK\n",
    "\n",
    "    # BEGIN SCALING & DATA PREPARATION BLOCK\n",
    "    print(\"Data Preparation\")\n",
    "    indices_train_H = helper.leaveFinite(opt.transform_series([train_data[0], train_data_ref[0]])).swapaxes(0, 1)\n",
    "    indices_train_S = helper.leaveFinite(opt.transform_series([train_data[1], train_data_ref[1]])).swapaxes(0, 1)\n",
    "    indices_test_H = helper.leaveFinite(opt.transform_series([test_data[0], test_data_ref[0]])).swapaxes(0, 1)\n",
    "    indices_test_S = helper.leaveFinite(opt.transform_series([test_data[1], test_data_ref[1]])).swapaxes(0, 1)\n",
    "\n",
    "    scaler = RobustScaler(unit_variance=True)\n",
    "\n",
    "    indices_train_H = scaler.fit_transform(indices_train_H)\n",
    "    indices_train_S = scaler.transform(indices_train_S)\n",
    "    indices_test_H = scaler.transform(indices_test_H)\n",
    "    indices_test_S = scaler.transform(indices_test_S)\n",
    "\n",
    "    train_X, train_y = helper.joinData(indices_train_H, indices_train_S)\n",
    "    test_X, test_y = helper.joinData(indices_test_H, indices_test_S)\n",
    "    # END SCALING & DATA PREPARATION BLOCK\n",
    "\n",
    "    # BEGIN MODEL TRAINING BLOCK\n",
    "    features_count = len(opt.selected_features)\n",
    "    print(\"Model Training\")\n",
    "    clf = MLPClassifier(tol=1e-2,\n",
    "                        learning_rate=\"adaptive\", \n",
    "                        activation='relu', \n",
    "                        hidden_layer_sizes=(2 * features_count), \n",
    "                        early_stopping=True, \n",
    "                        max_iter=60)\n",
    "    \n",
    "    clf.fit(train_X, train_y)\n",
    "    # END MODEL TRAINING BLOCK\n",
    "\n",
    "    # BEGIN MODEL EVALUATION BLOCK\n",
    "    print(\"Model Evaluation\")\n",
    "    predict_metrics = [(\"iou\", jaccard_score)]\n",
    "    predict_proba_metrics = [(\"pr_auc\", average_precision_score)]\n",
    "\n",
    "    pred_train = clf.predict(train_X)\n",
    "    pred_proba_train = clf.predict_proba(train_X)[:, 1]\n",
    "\n",
    "    pred_test = clf.predict(test_X)\n",
    "    pred_proba_test = clf.predict_proba(test_X)[:, 1]\n",
    "\n",
    "    metric_results = {}\n",
    "    for key, metric in predict_metrics:\n",
    "        metric_results[key + \" (train)\"] = metric(train_y, pred_train)\n",
    "        metric_results[key + \" (test)\"] = metric(test_y, pred_test)\n",
    "\n",
    "    for key, metric in predict_proba_metrics:\n",
    "        metric_results[key + \" (train)\"] = metric(train_y, pred_proba_train)\n",
    "        metric_results[key + \" (test)\"] = metric(test_y, pred_proba_test)\n",
    "    # END MODEL EVALUATION BLOCK\n",
    "\n",
    "    # BEGIN PRINTING BLOCK\n",
    "    metric_results[\"fitness\"] = opt.get_fitness_()\n",
    "    metric_results[\"feature_count\"] = len(opt.selected_features)\n",
    "    metric_results[\"features\"] = [int(f) for f in opt.selected_features]\n",
    "    for metric in metric_results.keys():\n",
    "        print(f\"    {metric}: {metric_results[metric]}\")\n",
    "\n",
    "    print(\"-\"*33)\n",
    "    # END PRINTING BLOCK\n",
    "\n",
    "    return metric_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of evaluations:  1\n",
      "---------------------------------\n",
      "START NEW MODEL\n",
      "INFO: 0.1 INDEP: 0.1\n",
      "Feature Optimization\n",
      "Avaible features: 5324\n",
      "Fitness (Gen 150): 4.387208725734177\n",
      "Data Preparation\n",
      "Model Training\n",
      "Model Evaluation\n",
      "    iou (train): 0.6451073506788844\n",
      "    iou (test): 0.5519338918856881\n",
      "    pr_auc (train): 0.8686522227302897\n",
      "    pr_auc (test): 0.7632305653850626\n",
      "    fitness: 4.387208725734177\n",
      "    feature_count: 31\n",
      "    features: [3684, 603, 1142, 3236, 735, 3969, 3786, 3094, 725, 2729, 344, 2257, 3403, 2353, 1187, 846, 254, 3274, 2670, 763, 3369, 984, 653, 3419, 877, 4018, 2546, 1452, 2096, 3087, 5288]\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "informativeness_values = [0.1]\n",
    "independency_values = [0.1]\n",
    "\n",
    "print(\"Num of evaluations: \", len(informativeness_values) * len(independency_values))\n",
    "\n",
    "result_matrix = [[None]*len(independency_values) for i in range(len(informativeness_values))]\n",
    "for i in range(len(informativeness_values)):\n",
    "    for j in range(len(independency_values)):\n",
    "        result_matrix[i][j] = evaluateModel(informativeness_values[i], independency_values[j])\n",
    "\n",
    "# with open(os.path.join(\"grid_search\", f\"hue_simp_normp4_16_1_2_eq_weighted_harmonic_mean.json\"), 'w') as fout:\n",
    "#     json.dump(result_matrix, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swiftt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
